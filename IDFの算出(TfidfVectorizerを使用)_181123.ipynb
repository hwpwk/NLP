{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 可視化用のライブラリ\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import neologdn\n",
    "import MeCab\n",
    "\n",
    "import re\n",
    "\n",
    "# テキスト解析\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surface</th>\n",
       "      <th>yomi</th>\n",
       "      <th>original</th>\n",
       "      <th>type</th>\n",
       "      <th>katsuyoukei</th>\n",
       "      <th>katsuyougata</th>\n",
       "      <th>内容</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neologd</td>\n",
       "      <td>ネオログディー</td>\n",
       "      <td>NEologd</td>\n",
       "      <td>名詞-固有名詞-一般</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>記号-一般</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tagger</td>\n",
       "      <td>タガー</td>\n",
       "      <td>tagger</td>\n",
       "      <td>名詞-固有名詞-一般</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>記号-一般</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>parse</td>\n",
       "      <td>パース</td>\n",
       "      <td>Parse</td>\n",
       "      <td>名詞-固有名詞-一般</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   surface     yomi original        type katsuyoukei katsuyougata  \\\n",
       "0  neologd  ネオログディー  NEologd  名詞-固有名詞-一般         NaN          NaN   \n",
       "1        _        _        _       記号-一般         NaN          NaN   \n",
       "2   tagger      タガー   tagger  名詞-固有名詞-一般         NaN          NaN   \n",
       "3        .        .        .       記号-一般         NaN          NaN   \n",
       "4    parse      パース    Parse  名詞-固有名詞-一般         NaN          NaN   \n",
       "\n",
       "                                                  内容  \n",
       "0  neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...  \n",
       "1  neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...  \n",
       "2  neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...  \n",
       "3  neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...  \n",
       "4  neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all_text_wakatigaki.csv',encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テキスト毎にわかち書きされた単語を結合\n",
    "参考URL：https://github.com/Salinger/found_it_project_06_crwl/blob/master/src/python_crawler_nlp.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>内容</th>\n",
       "      <th>wakati_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...</td>\n",
       "      <td>NEologd _ tagger . Parse ( text ) で 各 単語 の 原形 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、...</td>\n",
       "      <td>まずは Parse () で 分かち書き する た 単語 群 は 1つ の 文字列 型 に ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される</td>\n",
       "      <td>原形 、 品詞 など の 間 に は 「 \\ t 」 が 、 分かち書き する れる た 単...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid...</td>\n",
       "      <td>次に 邪魔 だ 文字 「\\ t 」 を 省く たい 。 よって 、 split ('\\ t ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  内容  \\\n",
       "0  neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...   \n",
       "1  まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、...   \n",
       "2     原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される   \n",
       "3  次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid...   \n",
       "\n",
       "                                        wakati_words  \n",
       "0  NEologd _ tagger . Parse ( text ) で 各 単語 の 原形 ...  \n",
       "1  まずは Parse () で 分かち書き する た 単語 群 は 1つ の 文字列 型 に ...  \n",
       "2  原形 、 品詞 など の 間 に は 「 \\ t 」 が 、 分かち書き する れる た 単...  \n",
       "3  次に 邪魔 だ 文字 「\\ t 」 を 省く たい 。 よって 、 split ('\\ t ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.groupbyでグループ化された[内容]毎の[original]カラムの各要素に対して文字列のリスト（配列）を一つの文字列に連結する「join」関数を各行（各要素）に対して実行する\n",
    "# join関数の使い方: '間に挿入する文字列'.join([連結したい文字列のリスト])\n",
    "text_wakati_df = df.groupby('内容')['original'].apply(lambda x: ' '.join(map(str, x))).reset_index()\n",
    "\n",
    "# カラム名を適切な名前に変更\n",
    "text_wakati_df = text_wakati_df.rename(columns={'original':'wakati_words'})\n",
    "\n",
    "# 確認\n",
    "text_wakati_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDFの実装(TfidfVectorizerを使用)\n",
    "参考URL：https://github.com/hwpwk/NLP/blob/master/TfidfVectorizer%E3%81%AB%E3%82%88%E3%82%8B%E6%96%87%E6%9B%B8%E3%81%AE%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E5%8C%96(TF-IDF)%2BDataFrame%E5%8C%96_parse%E3%81%A7%E5%BD%A2%E6%85%8B%E7%B4%A0%E8%A7%A3%E6%9E%90_181030.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期化\n",
    "# 変更(181121)\n",
    "# CountVectorizer や TfidfVectorizer は、デフォルトでは、一文字のトークンが除外されてしまうのでtoken_pattern=u'(?u)\\\\b\\\\w+\\\\b'を除外を阻止\n",
    "# TfidfVectorizerではデフォルトで英字の大文字は小文字に変換するのでlowercase=Falseを引数に与え大文字を大文字として処理\n",
    "# 参考URL：https://qiita.com/m__k/items/709a9cae184769e2243f\n",
    "vectorizer= TfidfVectorizer(token_pattern=u'(?u)\\\\b\\\\w+\\\\b', lowercase=False)\n",
    "\n",
    "\n",
    "# TfidfVectorizerを利用して単語と列番号の対応付けを実行 Document-Term Matrixを獲得できる\n",
    "tfidf_feature_vectors = vectorizer.fit_transform(text_wakati_df['wakati_words'])\n",
    "\n",
    "# どの単語を学習しているのかをvectorizer.get_feature_names()で確認できる\n",
    "# 後にデータフレームを作成する際にカラムとして使用する準備\n",
    "tfidf_vocabulary = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習単語とIDFを紐付け"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.91629073, 1.91629073, 1.91629073, 1.51082562, 1.51082562,\n",
       "       1.51082562, 1.91629073, 1.51082562, 1.91629073, 1.51082562,\n",
       "       1.91629073, 1.91629073, 1.22314355, 1.        , 1.51082562,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.51082562, 1.22314355,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.51082562, 1.91629073,\n",
       "       1.51082562, 1.        , 1.91629073, 1.22314355, 1.91629073,\n",
       "       1.91629073, 1.51082562, 1.91629073, 1.51082562, 1.91629073,\n",
       "       1.51082562, 1.91629073, 1.91629073, 1.22314355, 1.51082562,\n",
       "       1.91629073, 1.51082562, 1.51082562, 1.91629073, 1.51082562,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.51082562,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TfidfVectorizer関数後にfit_transformしたあとに_tfidf.idf_にアクセスすればIDF値を取得できる\n",
    "# 参考URL：https://qiita.com/m__k/items/22474ef67f07bc73602a\n",
    "idf = vectorizer._tfidf.idf_\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:1.916290731874155\n",
      "1つ:1.916290731874155\n",
      "NEologd:1.916290731874155\n",
      "Parse:1.5108256237659907\n",
      "_:1.5108256237659907\n",
      "n:1.5108256237659907\n",
      "split:1.916290731874155\n",
      "t:1.5108256237659907\n",
      "tagger:1.916290731874155\n",
      "text:1.5108256237659907\n",
      "wakatid:1.916290731874155\n",
      "いる:1.916290731874155\n",
      "が:1.2231435513142097\n",
      "する:1.0\n",
      "た:1.5108256237659907\n",
      "たい:1.916290731874155\n",
      "ため:1.916290731874155\n",
      "だ:1.916290731874155\n",
      "て:1.5108256237659907\n",
      "で:1.2231435513142097\n",
      "できる:1.916290731874155\n",
      "と:1.916290731874155\n",
      "ない:1.916290731874155\n",
      "など:1.5108256237659907\n",
      "なる:1.916290731874155\n",
      "に:1.5108256237659907\n",
      "の:1.0\n",
      "ので:1.916290731874155\n",
      "は:1.2231435513142097\n",
      "まずは:1.916290731874155\n",
      "よって:1.916290731874155\n",
      "れる:1.5108256237659907\n",
      "を:1.916290731874155\n",
      "リスト:1.5108256237659907\n",
      "使用:1.916290731874155\n",
      "分かち書き:1.5108256237659907\n",
      "区切り:1.916290731874155\n",
      "区切る:1.916290731874155\n",
      "単語:1.2231435513142097\n",
      "原形:1.5108256237659907\n",
      "各:1.916290731874155\n",
      "品詞:1.5108256237659907\n",
      "型:1.5108256237659907\n",
      "文字:1.916290731874155\n",
      "文字列:1.5108256237659907\n",
      "次に:1.916290731874155\n",
      "省く:1.916290731874155\n",
      "群:1.916290731874155\n",
      "行:1.916290731874155\n",
      "表示:1.5108256237659907\n",
      "連続:1.916290731874155\n",
      "邪魔:1.916290731874155\n",
      "間:1.916290731874155\n",
      "関数:1.916290731874155\n"
     ]
    }
   ],
   "source": [
    "# 紐付け方法1\n",
    "# 単純にzip関数で学習単語とそのIDFをfor文で表示\n",
    "for word, idf in zip(vectorizer.get_feature_names(), vectorizer._tfidf.idf_):\n",
    "    print(str(word) + ':' + str(idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 1.916290731874155,\n",
       " '1つ': 1.916290731874155,\n",
       " 'NEologd': 1.916290731874155,\n",
       " 'Parse': 1.5108256237659907,\n",
       " '_': 1.5108256237659907,\n",
       " 'n': 1.5108256237659907,\n",
       " 'split': 1.916290731874155,\n",
       " 't': 1.5108256237659907,\n",
       " 'tagger': 1.916290731874155,\n",
       " 'text': 1.5108256237659907,\n",
       " 'wakatid': 1.916290731874155,\n",
       " 'いる': 1.916290731874155,\n",
       " 'が': 1.2231435513142097,\n",
       " 'する': 1.0,\n",
       " 'た': 1.5108256237659907,\n",
       " 'たい': 1.916290731874155,\n",
       " 'ため': 1.916290731874155,\n",
       " 'だ': 1.916290731874155,\n",
       " 'て': 1.5108256237659907,\n",
       " 'で': 1.2231435513142097,\n",
       " 'できる': 1.916290731874155,\n",
       " 'と': 1.916290731874155,\n",
       " 'ない': 1.916290731874155,\n",
       " 'など': 1.5108256237659907,\n",
       " 'なる': 1.916290731874155,\n",
       " 'に': 1.5108256237659907,\n",
       " 'の': 1.0,\n",
       " 'ので': 1.916290731874155,\n",
       " 'は': 1.2231435513142097,\n",
       " 'まずは': 1.916290731874155,\n",
       " 'よって': 1.916290731874155,\n",
       " 'れる': 1.5108256237659907,\n",
       " 'を': 1.916290731874155,\n",
       " 'リスト': 1.5108256237659907,\n",
       " '使用': 1.916290731874155,\n",
       " '分かち書き': 1.5108256237659907,\n",
       " '区切り': 1.916290731874155,\n",
       " '区切る': 1.916290731874155,\n",
       " '単語': 1.2231435513142097,\n",
       " '原形': 1.5108256237659907,\n",
       " '各': 1.916290731874155,\n",
       " '品詞': 1.5108256237659907,\n",
       " '型': 1.5108256237659907,\n",
       " '文字': 1.916290731874155,\n",
       " '文字列': 1.5108256237659907,\n",
       " '次に': 1.916290731874155,\n",
       " '省く': 1.916290731874155,\n",
       " '群': 1.916290731874155,\n",
       " '行': 1.916290731874155,\n",
       " '表示': 1.5108256237659907,\n",
       " '連続': 1.916290731874155,\n",
       " '邪魔': 1.916290731874155,\n",
       " '間': 1.916290731874155,\n",
       " '関数': 1.916290731874155}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 紐付け方法2\n",
    "# 学習単語とそのIDFを辞書型に格納\n",
    "# 参考URL：https://qiita.com/m__k/items/22474ef67f07bc73602a\n",
    "word_idf_dict = {}\n",
    "for word, idf in zip(vectorizer.get_feature_names(), vectorizer._tfidf.idf_):\n",
    "    word_idf_dict[word] = idf\n",
    "\n",
    "word_idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
