{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 可視化用のライブラリ\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import neologdn\n",
    "import MeCab\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "# # プログレスバーのラベル設定\n",
    "tqdm_notebook.pandas(desc=\"progress: \")\n",
    "\n",
    "#前処理用ライブラリ\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 機械学習モデル関連ライブラリ\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import neighbors\n",
    "\n",
    "\n",
    "# モデル評価関連ライブラリ\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, auc, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 内容_id×全品詞の単語のデータフレームの読み込み\n",
    "std001_model_tfidf_df = pd.read_pickle('std001_model_tfidf_df.pkl')\n",
    "std001_model_tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [内容_id]をインデックスからカラムに移動\n",
    "std001_model_tfidf_df = std001_model_tfidf_df.reset_index()\n",
    "std001_model_tfidf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 次元削減のための準備\n",
    "DataFrameからarray型へ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "std001_model_tfidf_df_array = std001_model_tfidf_df.iloc[:, 1:].values# [内容]カラムのみarray型にしないため除外\n",
    "std001_model_tfidf_df_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 次元圧縮\n",
    "次元圧縮法として代表的な手法は3つ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.NMFで次元削減"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2次元に変換\n",
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=2, init='random', random_state=0)\n",
    "X_nmf = model.fit_transform(std001_model_tfidf_df_array)\n",
    "X_nmf[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.PCAで次元削減"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# まずはStandardScaler を利用し数値を標準化(平均が 0 で標準偏差・分散が 1 )\n",
    "# StandardScalerを使用すると負の値が出てくるのでtandardScaler後のNMFでの次元削減はできない\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sds = StandardScaler()\n",
    "X_sds = sds.fit_transform(std001_model_tfidf_df_array)\n",
    "X_sds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca\n",
    "# 2次元に変換\n",
    "from sklearn.decomposition import PCA\n",
    "model = PCA(n_components=2)\n",
    "X_pca = model.fit_transform(X_sds)\n",
    "X_pca[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.t-SNEで次元圧縮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler利用後の値を使用\n",
    "# 2次元に変換\n",
    "from sklearn.manifold import TSNE\n",
    "X_sne = TSNE(n_components=2).fit_transform(X_sds)\n",
    "X_sne[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 次元圧縮後の単語の値でクラスタリング\n",
    "今回はコサイン類似度を基準とした階層的凝集型クラスタリングを行って2つのクラスタに分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PCAによる次元圧縮後の値を使用\n",
    "# NMFによる次元削減後の値には２次元どちらも「０」であるレコードがあるためエラーが発生してしまうらしい\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "model = AgglomerativeClustering(n_clusters=2, linkage='average', affinity='cosine')\n",
    "y = model.fit_predict(X_pca)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 念のため\n",
    "# t-sneによる次元圧縮後の値を使用\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "model = AgglomerativeClustering(n_clusters=2, linkage='average', affinity='cosine')\n",
    "y2 = model.fit_predict(X_sne)\n",
    "y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 次元削減後の値とクラスタ番号を元データフレームと連結"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# まずはPCAによる次元圧縮後の値をデータフレームにしておく\n",
    "dimension_reduction_df = pd.DataFrame(X_pca, columns=['vec1', 'vec2'])\n",
    "dimension_reduction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 次にPCAによる次元圧縮後の値のみのデータフレームを[内容_id]カラムのみのデータフレームとインデックス番号をキーにして紐付ける\n",
    "# index をキーに結合したい場合は、DataFrame.joinを使用\n",
    "dimension_reduction_join_df = std001_model_tfidf_df[['内容_id']].join(dimension_reduction_df)\n",
    "dimension_reduction_join_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加えて、クラスタリング番号の値も紐付ける\n",
    "dimension_reduction_join_df['cluster'] = y\n",
    "dimension_reduction_join_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
