{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 可視化用のライブラリ\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import neologdn\n",
    "import MeCab\n",
    "\n",
    "import re\n",
    "\n",
    "# テキスト解析\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surface</th>\n",
       "      <th>yomi</th>\n",
       "      <th>original</th>\n",
       "      <th>type</th>\n",
       "      <th>katsuyoukei</th>\n",
       "      <th>katsuyougata</th>\n",
       "      <th>内容</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neologd</td>\n",
       "      <td>ネオログディー</td>\n",
       "      <td>NEologd</td>\n",
       "      <td>名詞-固有名詞-一般</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>記号-一般</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tagger</td>\n",
       "      <td>タガー</td>\n",
       "      <td>tagger</td>\n",
       "      <td>名詞-固有名詞-一般</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>記号-一般</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>parse</td>\n",
       "      <td>パース</td>\n",
       "      <td>Parse</td>\n",
       "      <td>名詞-固有名詞-一般</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   surface     yomi original        type katsuyoukei katsuyougata  \\\n",
       "0  neologd  ネオログディー  NEologd  名詞-固有名詞-一般         NaN          NaN   \n",
       "1        _        _        _       記号-一般         NaN          NaN   \n",
       "2   tagger      タガー   tagger  名詞-固有名詞-一般         NaN          NaN   \n",
       "3        .        .        .       記号-一般         NaN          NaN   \n",
       "4    parse      パース    Parse  名詞-固有名詞-一般         NaN          NaN   \n",
       "\n",
       "                                                  内容  \n",
       "0  neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...  \n",
       "1  neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...  \n",
       "2  neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...  \n",
       "3  neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...  \n",
       "4  neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all_text_wakatigaki.csv',encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テキスト毎にわかち書きされた単語を結合\n",
    "参考URL：https://github.com/Salinger/found_it_project_06_crwl/blob/master/src/python_crawler_nlp.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>内容</th>\n",
       "      <th>wakati_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...</td>\n",
       "      <td>NEologd _ tagger . Parse ( text ) で 各 単語 の 原形 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、...</td>\n",
       "      <td>まずは Parse () で 分かち書き する た 単語 群 は 1つ の 文字列 型 に ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される</td>\n",
       "      <td>原形 、 品詞 など の 間 に は 「 \\ t 」 が 、 分かち書き する れる た 単...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid...</td>\n",
       "      <td>次に 邪魔 だ 文字 「\\ t 」 を 省く たい 。 よって 、 split ('\\ t ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  内容  \\\n",
       "0  neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して...   \n",
       "1  まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、...   \n",
       "2     原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される   \n",
       "3  次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid...   \n",
       "\n",
       "                                        wakati_words  \n",
       "0  NEologd _ tagger . Parse ( text ) で 各 単語 の 原形 ...  \n",
       "1  まずは Parse () で 分かち書き する た 単語 群 は 1つ の 文字列 型 に ...  \n",
       "2  原形 、 品詞 など の 間 に は 「 \\ t 」 が 、 分かち書き する れる た 単...  \n",
       "3  次に 邪魔 だ 文字 「\\ t 」 を 省く たい 。 よって 、 split ('\\ t ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.groupbyでグループ化された[内容]毎の[original]に対して文字列のリスト（配列）を一つの文字列に連結する「join」関数を各行（各要素）に対して実行する\n",
    "# join関数の使い方: '間に挿入する文字列'.join([連結したい文字列のリスト])\n",
    "text_wakati_df = df.groupby('内容')['original'].apply(lambda x: ' '.join(map(str, x))).reset_index()\n",
    "\n",
    "# カラム名を適切な名前に変更\n",
    "text_wakati_df = text_wakati_df.rename(columns={'original':'wakati_words'})\n",
    "\n",
    "# 確認\n",
    "text_wakati_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDFの実装(TfidfVectorizerを使用)\n",
    "参考URL：https://github.com/hwpwk/NLP/blob/master/TfidfVectorizer%E3%81%AB%E3%82%88%E3%82%8B%E6%96%87%E6%9B%B8%E3%81%AE%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E5%8C%96(TF-IDF)%2BDataFrame%E5%8C%96_parse%E3%81%A7%E5%BD%A2%E6%85%8B%E7%B4%A0%E8%A7%A3%E6%9E%90_181030.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期化\n",
    "vectorizer= TfidfVectorizer()\n",
    "\n",
    "# TfidfVectorizerを利用して単語と列番号の対応付けを実行 Document-Term Matrixを獲得できる\n",
    "tfidf_feature_vectors = vectorizer.fit_transform(text_wakati_df['wakati_words'])\n",
    "\n",
    "# どの単語を学習しているのかをvectorizer.get_feature_names()で確認できる\n",
    "# 後にデータフレームを作成する際にカラムとして使用する準備\n",
    "tfidf_vocabulary = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## インデックスを元のテキスト、カラムを「わかち書きした単語」にしたデータフレームを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1つ</th>\n",
       "      <th>neologd</th>\n",
       "      <th>parse</th>\n",
       "      <th>split</th>\n",
       "      <th>tagger</th>\n",
       "      <th>text</th>\n",
       "      <th>wakatid</th>\n",
       "      <th>いる</th>\n",
       "      <th>する</th>\n",
       "      <th>たい</th>\n",
       "      <th>ため</th>\n",
       "      <th>できる</th>\n",
       "      <th>ない</th>\n",
       "      <th>など</th>\n",
       "      <th>なる</th>\n",
       "      <th>ので</th>\n",
       "      <th>まずは</th>\n",
       "      <th>よって</th>\n",
       "      <th>れる</th>\n",
       "      <th>リスト</th>\n",
       "      <th>使用</th>\n",
       "      <th>分かち書き</th>\n",
       "      <th>区切り</th>\n",
       "      <th>区切る</th>\n",
       "      <th>単語</th>\n",
       "      <th>原形</th>\n",
       "      <th>品詞</th>\n",
       "      <th>文字</th>\n",
       "      <th>文字列</th>\n",
       "      <th>次に</th>\n",
       "      <th>省く</th>\n",
       "      <th>表示</th>\n",
       "      <th>連続</th>\n",
       "      <th>邪魔</th>\n",
       "      <th>関数</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>内容</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して表示される</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.336187</td>\n",
       "      <td>0.265054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.336187</td>\n",
       "      <td>0.265054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214584</td>\n",
       "      <td>0.265054</td>\n",
       "      <td>0.265054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265054</td>\n",
       "      <td>0.336187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、リスト型にする</th>\n",
       "      <td>0.316496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316496</td>\n",
       "      <td>0.330322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316496</td>\n",
       "      <td>0.316496</td>\n",
       "      <td>0.316496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249529</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.316496</td>\n",
       "      <td>0.202015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258346</td>\n",
       "      <td>0.32768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.418307</td>\n",
       "      <td>0.258346</td>\n",
       "      <td>0.258346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid_textは文字列型ではなくリスト型のためsplit関数を使用できない</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151346</td>\n",
       "      <td>0.191963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100174</td>\n",
       "      <td>0.383927</td>\n",
       "      <td>0.191963</td>\n",
       "      <td>0.191963</td>\n",
       "      <td>0.383927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151346</td>\n",
       "      <td>0.383927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191963</td>\n",
       "      <td>0.151346</td>\n",
       "      <td>0.191963</td>\n",
       "      <td>0.191963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191963</td>\n",
       "      <td>0.191963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          1つ   neologd  \\\n",
       "内容                                                                       \n",
       "neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して表...  0.000000  0.336187   \n",
       "まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、リ...  0.316496  0.000000   \n",
       "原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される      0.000000  0.000000   \n",
       "次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid_...  0.000000  0.000000   \n",
       "\n",
       "                                                       parse     split  \\\n",
       "内容                                                                       \n",
       "neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して表...  0.265054  0.000000   \n",
       "まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、リ...  0.249529  0.000000   \n",
       "原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される      0.000000  0.000000   \n",
       "次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid_...  0.000000  0.383927   \n",
       "\n",
       "                                                      tagger      text  \\\n",
       "内容                                                                       \n",
       "neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して表...  0.336187  0.265054   \n",
       "まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、リ...  0.000000  0.000000   \n",
       "原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される      0.000000  0.000000   \n",
       "次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid_...  0.000000  0.151346   \n",
       "\n",
       "                                                     wakatid        いる  \\\n",
       "内容                                                                       \n",
       "neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して表...  0.000000  0.000000   \n",
       "まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、リ...  0.000000  0.316496   \n",
       "原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される      0.000000  0.000000   \n",
       "次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid_...  0.191963  0.000000   \n",
       "\n",
       "                                                          する        たい  \\\n",
       "内容                                                                       \n",
       "neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して表...  0.350873  0.000000   \n",
       "まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、リ...  0.330322  0.000000   \n",
       "原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される      0.341994  0.000000   \n",
       "次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid_...  0.100174  0.383927   \n",
       "\n",
       "                                                          ため       できる  \\\n",
       "内容                                                                       \n",
       "neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して表...  0.000000  0.000000   \n",
       "まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、リ...  0.000000  0.000000   \n",
       "原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される      0.000000  0.000000   \n",
       "次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid_...  0.191963  0.191963   \n",
       "\n",
       "                                                          ない        など  \\\n",
       "内容                                                                       \n",
       "neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して表...  0.000000  0.265054   \n",
       "まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、リ...  0.000000  0.000000   \n",
       "原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される      0.000000  0.258346   \n",
       "次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid_...  0.383927  0.000000   \n",
       "\n",
       "                                                          なる        ので  \\\n",
       "内容                                                                       \n",
       "neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して表...  0.000000  0.000000   \n",
       "まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、リ...  0.316496  0.316496   \n",
       "原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される      0.000000  0.000000   \n",
       "次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid_...  0.000000  0.000000   \n",
       "\n",
       "                                                         まずは       よって  \\\n",
       "内容                                                                       \n",
       "neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して表...  0.000000  0.000000   \n",
       "まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、リ...  0.316496  0.000000   \n",
       "原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される      0.000000  0.000000   \n",
       "次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid_...  0.000000  0.191963   \n",
       "\n",
       "                                                          れる       リスト  \\\n",
       "内容                                                                       \n",
       "neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して表...  0.265054  0.000000   \n",
       "まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、リ...  0.000000  0.249529   \n",
       "原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される      0.516693  0.000000   \n",
       "次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid_...  0.000000  0.151346   \n",
       "\n",
       "                                                          使用     分かち書き  \\\n",
       "内容                                                                       \n",
       "neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して表...  0.000000  0.000000   \n",
       "まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、リ...  0.000000  0.249529   \n",
       "原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される      0.000000  0.258346   \n",
       "次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid_...  0.383927  0.000000   \n",
       "\n",
       "                                                        区切り       区切る  \\\n",
       "内容                                                                      \n",
       "neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して表...  0.00000  0.000000   \n",
       "まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、リ...  0.00000  0.316496   \n",
       "原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される      0.32768  0.000000   \n",
       "次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid_...  0.00000  0.000000   \n",
       "\n",
       "                                                          単語        原形  \\\n",
       "内容                                                                       \n",
       "neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して表...  0.214584  0.265054   \n",
       "まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、リ...  0.202015  0.000000   \n",
       "原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される      0.418307  0.258346   \n",
       "次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid_...  0.000000  0.000000   \n",
       "\n",
       "                                                          品詞        文字  \\\n",
       "内容                                                                       \n",
       "neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して表...  0.265054  0.000000   \n",
       "まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、リ...  0.000000  0.000000   \n",
       "原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される      0.258346  0.000000   \n",
       "次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid_...  0.000000  0.191963   \n",
       "\n",
       "                                                         文字列        次に  \\\n",
       "内容                                                                       \n",
       "neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して表...  0.000000  0.000000   \n",
       "まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、リ...  0.249529  0.000000   \n",
       "原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される      0.000000  0.000000   \n",
       "次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid_...  0.151346  0.191963   \n",
       "\n",
       "                                                          省く        表示  \\\n",
       "内容                                                                       \n",
       "neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して表...  0.000000  0.265054   \n",
       "まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、リ...  0.000000  0.000000   \n",
       "原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される      0.000000  0.258346   \n",
       "次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid_...  0.191963  0.000000   \n",
       "\n",
       "                                                          連続        邪魔  \\\n",
       "内容                                                                       \n",
       "neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して表...  0.336187  0.000000   \n",
       "まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、リ...  0.000000  0.000000   \n",
       "原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される      0.000000  0.000000   \n",
       "次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid_...  0.000000  0.191963   \n",
       "\n",
       "                                                          関数  \n",
       "内容                                                            \n",
       "neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して表...  0.000000  \n",
       "まずはparse()で分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、リ...  0.000000  \n",
       "原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される      0.000000  \n",
       "次に邪魔な文字「\\t」を省きたい。よって、split('\\t')を使用したいがwakatid_...  0.191963  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df = pd.DataFrame(tfidf_feature_vectors.toarray(), index=text_wakati_df['内容'],  columns=tfidf_vocabulary)\n",
    "\n",
    "# デフォルトだとカラムの表示数が省略されるため最大表示列数の指定（ここでは100列を指定）\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "# 確認\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
