{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import neologdn\n",
    "import MeCab\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 日誌サンプルデータの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoding='utf-8'で上手くいった\n",
    "diary_df = pd.read_csv('SBI_Financial statement_201903.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>国内経済が緩やかに回復するなか、マーケット環境は、米国と中国の貿易摩擦問題に対する警戒感等か...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>このような環境の中、当社業績においては、ホールセールビジネスの拡大、トレーディング収益や金融...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>当社は引続き他社を大きく上回る高いシェアを維持し、35.9％のシェアを獲得。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>先物・オプションの委託個人売買代金シェアは、引き続き高水準を維持。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>投資信託残高の四半期末残高は過去最高を更新し、信託報酬は高水準を維持。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018年4月から2018年6月までの上場会社数は20社。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>同期間のSBI証券引受関与率は100％と 引き続き業界トップ。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  国内経済が緩やかに回復するなか、マーケット環境は、米国と中国の貿易摩擦問題に対する警戒感等か...\n",
       "1  このような環境の中、当社業績においては、ホールセールビジネスの拡大、トレーディング収益や金融...\n",
       "2             当社は引続き他社を大きく上回る高いシェアを維持し、35.9％のシェアを獲得。\n",
       "3                  先物・オプションの委託個人売買代金シェアは、引き続き高水準を維持。\n",
       "4                投資信託残高の四半期末残高は過去最高を更新し、信託報酬は高水準を維持。\n",
       "5                      2018年4月から2018年6月までの上場会社数は20社。\n",
       "6                    同期間のSBI証券引受関与率は100％と 引き続き業界トップ。"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MeCabにかける前準備としてneologdn.normalize()を使用して文章全体を正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_diary_normalization(text):\n",
    "    diary_normalization = neologdn.normalize(text)\n",
    "    return diary_normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MeCab + neologdで形態素解析し、不要文字を削除した上で1単語（とその読み、原形、品詞）毎にリストに格納"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neologd_tagger = MeCab.Tagger('-Ochasen -d C:\\mecab-ipadic-neologd')\n",
    "\n",
    "def mecabed_diary_list(diary_normalization):\n",
    "    mecabed_diary = neologd_tagger.parse(diary_normalization)\n",
    "    mecabed_diary_list = mecabed_diary.split('\\n')\n",
    "    mecabed_diary_list2 = mecabed_diary_list[0:-2] # EOSと’’(空白単語)を除外\n",
    "    \n",
    "## 各単語、用語を\\tとカンマ「,」で区切り、原形のみを抽出して辞書型にして初期化したリストに格納するfor文をこの後に追加\n",
    "# mecabed_diary_list2は['社長\\tシャチョウ\\t社長\\t名詞-一般\\t\\t',  'が\\tガ\\tが\\t助詞-格助詞-一般\\t\\t',・・・]というリストの形式になっている\n",
    "# これについて、mecabed_diary_list2の\n",
    "# 1番目の要素を['社長', 'シャチョウ', '社長', '名詞-一般', '', ''] \n",
    "# 2番目の要素を['が', 'ガ', 'が', '助詞-格助詞-一般', '', '']\n",
    "# というような1単語、1用語毎に区切られたリストの形式にしたい\n",
    "\n",
    "# re.split()は第一引数に正規表現パターン、第二引数に対象の文字列を指定\n",
    "# 複数の異なる区切り文字（文字列）で分割させたい場合に使う\n",
    "# パターンを「|」で区切るといずれかのパターンにマッチする\n",
    "# 各パターンには正規表現の特殊文字を使うことももちろん可能だが、文字列をそのまま指定することも可能\n",
    "# 参考：https://note.nkmk.me/python-split-rsplit-splitlines-re/\n",
    "    diclist = []\n",
    "    for word in mecabed_diary_list2:\n",
    "        l = re.split('\\t|,',word) # 各単語、用語は\\tとカンマ「,」で区切られてるのでこれらの文字で区切る\n",
    "        d = {'BaseForm':l[2]} # リストに{BaseForm:xx}といった形式で格納したいためリストの中身を辞書型{}にする\n",
    "        diclist.append(d)\n",
    "    return diclist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 感情極性辞書データの読み込み、 各単語とそのスコアを辞書型で格納"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PN_df = pd.read_csv('posi_nega_dic.csv')\n",
    "word_list = list(PN_df['word']) # list型\n",
    "score_list = list(PN_df['score']) #list型\n",
    "PN_dict = dict(zip(word_list, score_list)) #list型とlist型をdict(zip())関数に適用させるとdictionary型に"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 日誌サンプルを形態素解析した単語と感情極性辞書の単語のスコアを紐づける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_score_dic(diclist):\n",
    "    diclist_new = []\n",
    "\n",
    "    for word in diclist:\n",
    "        base = word['BaseForm']  # list型のdiclistの要素1つ1つは辞書型なのでword['key']という書き方でkeyに紐づくvalueを抽出できる\n",
    "        if base in PN_dict:\n",
    "            weight = float(PN_dict[base])  \n",
    "        else:\n",
    "            weight = 'NAN'             # その語がPN_dict(感性極性辞書)になかった場合\n",
    "        word['Weight'] = weight\n",
    "        diclist_new.append(word)\n",
    "    return diclist_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 感情極性辞書に含まれる単語のみ残す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_word_dic(diclist_new):\n",
    "    dictlist_add_weight_list =[]\n",
    "    \n",
    "    # df['xx']=='xx' の否定は  df['xx']!='xx'\n",
    "    for word in diclist_new:\n",
    "        if word['Weight'] != 'NAN' :   # wordは辞書型なのでdiclist_new['Weight'] とkeyを指定したときのvalueを抽出できる書き方ができる、便利\n",
    "            dictlist_add_weight_list.append(word)\n",
    "    return dictlist_add_weight_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単語のスコアを抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weight(dictlist_add_weight_list):\n",
    "    weight_list = []\n",
    "\n",
    "    for score in dictlist_add_weight_list:\n",
    "        weight = float(score['Weight'])\n",
    "        weight_list.append(weight)\n",
    "    return weight_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 単語のスコアの平均を算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean(weight_list):\n",
    "    #global weight_mean #weight_mean = str(0) とすれば記述する必要なし\n",
    "    if len(dictlist_add_weight_list) > 0:\n",
    "        weight_mean = np.mean(weight_list)\n",
    "    else:\n",
    "        # weight_mean =='NA'\n",
    "        weight_mean = str(0) # weight_mean =='NA'だと1つ下の関数実行部分で「'weight_mean' referenced before assignment」とエラー\n",
    "    return weight_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 日誌データのテキスト１つずつ関数を実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_list= []\n",
    "\n",
    "for diary in diary_df['text']:\n",
    "    diary_normalization = get_diary_normalization(diary)    \n",
    "    diclist = mecabed_diary_list(diary_normalization)    \n",
    "    diclist_new = get_word_score_dic(diclist)    \n",
    "    dictlist_add_weight_list = delete_word_dic(diclist_new)    \n",
    "    weight_list = dictlist_add_weight_list = get_weight(dictlist_add_weight_list)    \n",
    "    score = get_mean(weight_list)\n",
    "    score_list.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.46554470000000003\n",
      "-0.27814381818181827\n",
      "-0.25576150000000003\n",
      "-0.31583062\n",
      "-0.1432513333333333\n",
      "-0.6789305\n",
      "-0.48560359999999997\n"
     ]
    }
   ],
   "source": [
    "for score in score_list:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = pd.read_csv('SBI_Financial statement_201903.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output['score'] = score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>国内経済が緩やかに回復するなか、マーケット環境は、米国と中国の貿易摩擦問題に対する警戒感等か...</td>\n",
       "      <td>-0.465545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>このような環境の中、当社業績においては、ホールセールビジネスの拡大、トレーディング収益や金融...</td>\n",
       "      <td>-0.278144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>当社は引続き他社を大きく上回る高いシェアを維持し、35.9％のシェアを獲得。</td>\n",
       "      <td>-0.255762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>先物・オプションの委託個人売買代金シェアは、引き続き高水準を維持。</td>\n",
       "      <td>-0.315831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>投資信託残高の四半期末残高は過去最高を更新し、信託報酬は高水準を維持。</td>\n",
       "      <td>-0.143251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018年4月から2018年6月までの上場会社数は20社。</td>\n",
       "      <td>-0.678930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>同期間のSBI証券引受関与率は100％と 引き続き業界トップ。</td>\n",
       "      <td>-0.485604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     score\n",
       "0  国内経済が緩やかに回復するなか、マーケット環境は、米国と中国の貿易摩擦問題に対する警戒感等か... -0.465545\n",
       "1  このような環境の中、当社業績においては、ホールセールビジネスの拡大、トレーディング収益や金融... -0.278144\n",
       "2             当社は引続き他社を大きく上回る高いシェアを維持し、35.9％のシェアを獲得。 -0.255762\n",
       "3                  先物・オプションの委託個人売買代金シェアは、引き続き高水準を維持。 -0.315831\n",
       "4                投資信託残高の四半期末残高は過去最高を更新し、信託報酬は高水準を維持。 -0.143251\n",
       "5                      2018年4月から2018年6月までの上場会社数は20社。 -0.678930\n",
       "6                    同期間のSBI証券引受関与率は100％と 引き続き業界トップ。 -0.485604"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csvファイルで出力\n",
    "# 出力の際、csvファイル読み込み時と同じ encoding='utf-8'にすると日本語文字化けが発生\n",
    "# encoding='shift-jis'で日本語文字化けが解消\n",
    "# 自動でindexがついてきたのでそれを削除\n",
    "output.to_csv('SBI_Financial statement_201903_add_score.csv', encoding='shift-jis', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 参考URL:https://www.statsbeginner.net/entry/2017/05/07/091435"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
