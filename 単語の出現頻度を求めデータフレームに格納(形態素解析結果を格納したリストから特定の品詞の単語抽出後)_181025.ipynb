{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import neologdn\n",
    "import MeCab\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text='「第一種過誤」を「αエラー」ともいうのですが、「α」をあわてんぼうの「あ」とかけて、あわてんぼうで、本当はない、2集団の差異をあるように判定してしまう。という論理です。一方「第二種過誤」は「βエラー」ともいいますが、「ベーター」をぼんやりとかけて、ぼんやりのβとしています。こちらも、ぼんやりしていて、本当はあるはずの貴重な2集団の差異！を見逃してしまう様を表現しています。'\n",
    "# 引用URL：http://www.kokushi.space/?p=1165"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### neologdnで文章の正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_normalization = neologdn.normalize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mecab + neologd 辞書による形態素解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neologd_tagger = MeCab.Tagger('-Ochasen -d C:\\mecab-ipadic-neologd')\n",
    "\n",
    "# neologd_tagger.parse(text)で各単語の原形、品詞などが1行で連続して表示される\n",
    "# 原形、品詞などの間には「\\t」が、分かち書きされた単語と単語の区切りには「\\n」が表示される\n",
    "# まずはparseで分かち書きした単語群は1つの文字列型になっているので「\\n」で区切り、リスト型にする\n",
    "wakati_text = neologd_tagger.parse(text_normalization).split('\\n')\n",
    "\n",
    "# 「\\n」で区切り、リスト型にした結果の例は下記\n",
    "# ['空い\\tアイ\\t空く\\t動詞-自立\\t五段・カ行イ音便\\t連用タ接続', ：リスト0番目\n",
    "# 'た\\tタ\\tた\\t助動詞\\t特殊・タ\\t基本形',：リスト1番目\n",
    "# '時間\\tジカン\\t時間\\t名詞-副詞可能\\t\\t',：リスト2番目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 形態素解析結果を格納したリストから特定の品詞を抽出\n",
    "2つのパターンを記述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.形態素解析結果を格納したリストから特定の品詞（品詞詳細部分まで考慮に入れた場合）のみ抽出\n",
    "\n",
    "- 「単語、品詞、原形、」などの一連の出力結果を格納したリスト：wakati_list\n",
    "- 「原形」のみ格納したリスト：original_form_list\n",
    "\n",
    "これら2つのリストを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 抽出したい品詞のリストを作成（完全一致）\n",
    "# 品詞参考URL：http://miner.hatenablog.com/entry/323\n",
    "hinshi_list = ['名詞-一般', '名詞-形容動詞語幹', '名詞-固有名詞-一般',  '名詞-サ変接続', '形容詞-自立', '形容詞-接尾', '形容詞-非自立', '動詞-自立', '動詞-接尾', '動詞-非自立', '副詞-一般', '副詞-助詞類接続']\n",
    "# hinshi_list = ('名詞-一般', '名詞-サ変接続', '名詞-固有名詞', '名詞-形容動詞語幹'...)とタプルでも同じ結果\n",
    "\n",
    "wakati_list = []# 「単語、品詞、原形、」などの一連の出力結果を格納\n",
    "original_form_list =[]# 「原形」のみ格納\n",
    "\n",
    "# parse() の出力結果の最後は「EOS」という文字のみ\n",
    "# EOSのとき、pos = wakati.split('\\t')[3]の要素はないので下記forループを実行すると「list index out of range」とエラーを発生させてしまう\n",
    "# よってEOSのときは条件分岐if~breakでforループから抜け出すよう記述\n",
    "for wakati in wakati_text:\n",
    "    surface = wakati.split('\\t')[0]\n",
    "    if surface == 'EOS':\n",
    "        break\n",
    "    else:\n",
    "        pos = wakati.split('\\t')[3]\n",
    "        if pos in hinshi_list:# posはhinshi_listの中の要素と完全一致していないと抽出できない\n",
    "            wakati_list.append(wakati)\n",
    "            original_form_list.append(wakati.split('\\t')[2])# 「原形」はインデックス2番目の要素にあるので"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['第一種過誤',\n",
       " 'エラー',\n",
       " 'いう',\n",
       " 'あわ',\n",
       " 'てんぼう',\n",
       " 'かける',\n",
       " 'てんぼう',\n",
       " '本当は',\n",
       " 'ない',\n",
       " '集団',\n",
       " '差異',\n",
       " 'ある',\n",
       " '判定',\n",
       " 'する',\n",
       " 'しまう',\n",
       " '論理',\n",
       " '第二種',\n",
       " '過誤',\n",
       " 'エラー',\n",
       " 'いう',\n",
       " 'ベーター',\n",
       " 'ぼんやり',\n",
       " 'かける',\n",
       " 'ぼんやり',\n",
       " 'する',\n",
       " 'いる',\n",
       " 'ぼんやり',\n",
       " 'する',\n",
       " 'いる',\n",
       " '本当は',\n",
       " 'ある',\n",
       " '貴重',\n",
       " '集団',\n",
       " '差異',\n",
       " '見逃す',\n",
       " 'しまう',\n",
       " '表現',\n",
       " 'する',\n",
       " 'いる']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_form_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.形態素解析結果を格納したリストから特定の品詞（純粋な品詞名）のみ抽出\n",
    "- 「単語、品詞、原形、」などの一連の出力結果を格納したリスト：wakati_list\n",
    "- 「原形」のみ格納したリスト：original_form_list\n",
    "\n",
    "これら2つのリストを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "only_hinshi_list = ['名詞', '形容詞', '動詞', '副詞']\n",
    "\n",
    "\n",
    "wakati_list2 = []# 「単語、品詞、原形、」などの一連の出力結果を格納\n",
    "original_form_list2 =[]# 「原形」のみ格納\n",
    "\n",
    "# parse() の出力結果の最後は「EOS」という文字のみ\n",
    "# EOSのとき、pos = wakati.split('\\t')[3]の要素はないので下記forループを実行すると「list index out of range」とエラーを発生させてしまう\n",
    "# よってEOSのときは条件分岐if~breakでforループから抜け出すよう記述\n",
    "\n",
    "# wakati.split('\\t')[3]の要素を見ると「名詞-固有名詞-一般」となっているので純粋な品詞名は「-」で区切ったときの0番目の要素にある\n",
    "# よってpos.split('-')[0]にすることで純粋な品詞名['名詞', '形容詞', '動詞', '副詞']を指定できる\n",
    "# 参考URL：https://teratail.com/questions/91987\n",
    "for wakati in wakati_text:\n",
    "    surface = wakati.split('\\t')[0]\n",
    "    if surface == 'EOS':\n",
    "        break\n",
    "    else:\n",
    "        pos = wakati.split('\\t')[3]\n",
    "        if pos.split('-')[0] in only_hinshi_list:\n",
    "            wakati_list2.append(wakati)\n",
    "            original_form_list2.append(wakati.split('\\t')[2])# 「原形」はインデックス2番目の要素にあるので"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['第一種過誤',\n",
       " 'エラー',\n",
       " 'いう',\n",
       " 'の',\n",
       " 'あわ',\n",
       " 'てんぼう',\n",
       " 'かける',\n",
       " 'あわ',\n",
       " 'てんぼう',\n",
       " '本当は',\n",
       " 'ない',\n",
       " '2',\n",
       " '集団',\n",
       " '差異',\n",
       " 'ある',\n",
       " 'よう',\n",
       " '判定',\n",
       " 'する',\n",
       " 'しまう',\n",
       " '論理',\n",
       " '第二種',\n",
       " '過誤',\n",
       " 'エラー',\n",
       " 'いう',\n",
       " 'ベーター',\n",
       " 'ぼんやり',\n",
       " 'かける',\n",
       " 'ぼんやり',\n",
       " 'する',\n",
       " 'いる',\n",
       " 'こちら',\n",
       " 'ぼんやり',\n",
       " 'する',\n",
       " 'いる',\n",
       " '本当は',\n",
       " 'ある',\n",
       " 'はず',\n",
       " '貴重',\n",
       " '2',\n",
       " '集団',\n",
       " '差異',\n",
       " '見逃す',\n",
       " 'しまう',\n",
       " '様',\n",
       " '表現',\n",
       " 'する',\n",
       " 'いる']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_form_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 単語の出現頻度を求め、それをデータフレームに格納"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('する', 4),\n",
       " ('ぼんやり', 3),\n",
       " ('いる', 3),\n",
       " ('エラー', 2),\n",
       " ('いう', 2),\n",
       " ('てんぼう', 2),\n",
       " ('かける', 2),\n",
       " ('本当は', 2),\n",
       " ('集団', 2),\n",
       " ('差異', 2),\n",
       " ('ある', 2),\n",
       " ('しまう', 2),\n",
       " ('第一種過誤', 1),\n",
       " ('あわ', 1),\n",
       " ('ない', 1),\n",
       " ('判定', 1),\n",
       " ('論理', 1),\n",
       " ('第二種', 1),\n",
       " ('過誤', 1),\n",
       " ('ベーター', 1),\n",
       " ('貴重', 1),\n",
       " ('見逃す', 1),\n",
       " ('表現', 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "count = collections.Counter(original_form_list)\n",
    "word_count_list = count.most_common()\n",
    "word_count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>する</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ぼんやり</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>いる</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>エラー</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>いう</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>てんぼう</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>かける</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>本当は</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>集団</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>差異</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ある</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>しまう</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>第一種過誤</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>あわ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ない</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>判定</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>論理</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>第二種</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>過誤</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ベーター</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>貴重</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>見逃す</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>表現</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  count\n",
       "0      する      4\n",
       "1    ぼんやり      3\n",
       "2      いる      3\n",
       "3     エラー      2\n",
       "4      いう      2\n",
       "5    てんぼう      2\n",
       "6     かける      2\n",
       "7     本当は      2\n",
       "8      集団      2\n",
       "9      差異      2\n",
       "10     ある      2\n",
       "11    しまう      2\n",
       "12  第一種過誤      1\n",
       "13     あわ      1\n",
       "14     ない      1\n",
       "15     判定      1\n",
       "16     論理      1\n",
       "17    第二種      1\n",
       "18     過誤      1\n",
       "19   ベーター      1\n",
       "20     貴重      1\n",
       "21    見逃す      1\n",
       "22     表現      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_df = pd.DataFrame(word_count_list, columns=['word', 'count'])\n",
    "word_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
